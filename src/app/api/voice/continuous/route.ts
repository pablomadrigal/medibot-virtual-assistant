import { NextRequest, NextResponse } from 'next/server';
import { getOpenAI } from '@/lib/ai/utils';

// Medical consultation system prompt in Spanish
const getSystemPrompt = (step: string) => {
  const basePrompt = `
Eres un asistente m√©dico virtual profesional dise√±ado para ayudar a pacientes con consultas iniciales en espa√±ol.

INSTRUCCIONES IMPORTANTES:
- Mant√©n respuestas CORTAS y CONCISAS (m√°ximo 2-3 frases)
- S√© emp√°tico y profesional
- Haz UNA pregunta espec√≠fica a la vez
- Nunca proporciones diagn√≥sticos definitivos
- Siempre recomienda consultar con un m√©dico para problemas serios
- Habla √∫nicamente en espa√±ol
- Responde de forma natural y conversacional

RESPONDE DE FORMA BREVE Y NATURAL, como si fueras un doctor real hablando con un paciente.
`;

  switch (step) {
    case 'patient-input':
      return basePrompt + `
PASO ACTUAL: Recopilaci√≥n de informaci√≥n del paciente
OBJETIVO: Recopilar s√≠ntomas, historial m√©dico, medicamentos actuales
PREGUNTAS A HACER:
- S√≠ntomas principales y duraci√≥n
- Historial m√©dico relevante
- Medicamentos actuales
- Alergias conocidas
- Factores de riesgo (viajes, exposici√≥n, etc.)

CUANDO LA INFORMACI√ìN EST√â COMPLETA, di: "He recopilado toda la informaci√≥n necesaria. Ahora proceder√© a realizar la evaluaci√≥n m√©dica."
`;
    case 'doctor-review':
      return basePrompt + `
PASO ACTUAL: An√°lisis m√©dico por el doctor
OBJETIVO: Analizar la informaci√≥n recopilada y proporcionar evaluaci√≥n
ACTIVIDADES:
- Revisar s√≠ntomas reportados
- Evaluar posibles diagn√≥sticos
- Identificar factores de riesgo
- Determinar urgencia de atenci√≥n m√©dica

CUANDO LA EVALUACI√ìN EST√â COMPLETA, di: "He completado la evaluaci√≥n m√©dica. Ahora proceder√© a generar las recomendaciones y prescripci√≥n."
`;
    case 'prescription':
      return basePrompt + `
PASO ACTUAL: Generaci√≥n de prescripci√≥n m√©dica
OBJETIVO: Proporcionar recomendaciones y prescripci√≥n
INCLUIR:
- Diagn√≥stico preliminar
- Recomendaciones de tratamiento
- Medicamentos sugeridos (si aplica)
- Referencias a especialistas (si necesario)
- Instrucciones de seguimiento

CUANDO LA PRESCRIPCI√ìN EST√â COMPLETA, di: "He completado la prescripci√≥n m√©dica. Su consulta ha terminado."
`;
    default:
      return basePrompt;
  }
};

export async function POST(request: NextRequest) {
  try {
    console.log('üîç Continuous voice processing request received');
    
    const body = await request.json();
    console.log('üìã Request body parsed successfully');
    
    const {
      audioData,
      conversationHistory = [],
      consultationStep = 'patient-input',
      isText = false,
      userText = '',
      sessionId
    } = body;
    
    console.log('üéØ Processing parameters:', {
      hasAudioData: !!audioData,
      conversationHistoryLength: conversationHistory.length,
      consultationStep,
      isText,
      hasUserText: !!userText,
      sessionId
    });

    // Convert conversation history to OpenAI format
    const processedHistory = conversationHistory
      .filter((msg: any) => msg && (msg.content || msg.text) && (msg.content?.trim() !== '' || msg.text?.trim() !== ''))
      .map((msg: any) => ({
        role: msg.role === 'agent' ? 'assistant' : msg.role,
        content: msg.content || msg.text || ''
      }));

    let finalUserText = userText;

    // Process audio if provided
    if (audioData && !isText) {
      try {
        console.log('üé§ Processing audio data...');
        
        // Convert base64 audio to buffer
        const audioBuffer = Buffer.from(audioData, 'base64');
        
        // Create a temporary file-like object for OpenAI
        const audioFile = new Blob([audioBuffer], { type: 'audio/wav' });
        
        // Convert to File object
        const file = new File([audioFile], 'audio.wav', { type: 'audio/wav' });
        
        // Transcribe using Whisper
        const openai = getOpenAI();
        const transcription = await openai.audio.transcriptions.create({
          file: file,
          model: 'whisper-1',
          language: 'es'
        });
        
        finalUserText = transcription.text;
        console.log('‚úÖ Audio transcription completed:', finalUserText);
      } catch (audioError) {
        console.error('‚ùå Audio processing error:', audioError);
        return NextResponse.json({
          error: 'Error procesando el audio. Int√©ntelo de nuevo.',
          success: false
        }, { status: 500 });
      }
    }

    if (!finalUserText.trim()) {
      return NextResponse.json({
        error: 'No se detect√≥ texto en el audio. ¬øPuede repetir por favor?',
        success: false
      });
    }

    console.log(`üë§ Usuario dijo: ${finalUserText}`);

    // Generate AI response
    console.log('üß† Generating AI response...');
    
    const messages = [
      { role: 'system', content: getSystemPrompt(consultationStep) },
      ...processedHistory.slice(-8), // Keep last 8 messages for context
      { role: 'user', content: finalUserText }
    ];

    let agentResponse = '';
    try {
      const openai = getOpenAI();
      const completion = await openai.chat.completions.create({
        model: 'gpt-4o-mini', // Using faster model for real-time responses
        messages: messages as any,
        max_tokens: 120,
        temperature: 0.7
      });

      agentResponse = completion.choices[0].message?.content || 'Lo siento, no pude procesar su consulta.';
      console.log(`ü§ñ Agente respondi√≥: ${agentResponse}`);
    } catch (gptError) {
      console.error('‚ùå GPT API error:', gptError);
      throw gptError;
    }

    // Convert response to speech
    console.log('üîä Converting response to speech...');
    let audioBase64 = '';
    try {
      const openai = getOpenAI();
      const speechResponse = await openai.audio.speech.create({
        model: 'tts-1',
        voice: 'alloy',
        input: agentResponse
      });

      const audioBuffer = Buffer.from(await speechResponse.arrayBuffer());
      audioBase64 = audioBuffer.toString('base64');
      console.log('‚úÖ TTS conversion completed');
    } catch (ttsError) {
      console.error('‚ùå TTS API error:', ttsError);
      // Continue without audio if TTS fails
    }

    // Check for step completion
    let stepComplete = false;
    let nextStep = consultationStep;
    let analysisData = null;
    
    const completionKeywords = {
      'patient-input': ['informaci√≥n completa', 'datos suficientes', 'informaci√≥n necesaria', 'recopilaci√≥n completa', 'proceder√© a realizar la evaluaci√≥n m√©dica'],
      'doctor-review': ['evaluaci√≥n completa', 'an√°lisis terminado', 'revisi√≥n completada', 'diagn√≥stico preliminar', 'proceder√© a generar las recomendaciones'],
      'prescription': ['prescripci√≥n completa', 'recomendaciones finales', 'tratamiento definido', 'consulta terminada', 'consulta ha terminado']
    };
    
    const currentKeywords = completionKeywords[consultationStep as keyof typeof completionKeywords] || [];
    const responseLower = agentResponse.toLowerCase();
    
    if (currentKeywords.some(keyword => responseLower.includes(keyword))) {
      stepComplete = true;
    }
    
    // Generate analysis data when step is complete
    if (stepComplete) {
      try {
        if (consultationStep === 'patient-input') {
          const patientDescription = processedHistory
            .filter((msg: any) => msg.role === 'user')
            .map((msg: any) => msg.content)
            .join(' ');
          
          const analysisResponse = await fetch(`${process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'}/api/ai/patient-analysis`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              patientDescription: patientDescription,
              symptoms: extractSymptoms(processedHistory),
              medicalHistory: extractMedicalHistory(processedHistory),
              currentMedications: extractMedications(processedHistory)
            })
          });
          
          if (analysisResponse.ok) {
            const result = await analysisResponse.json();
            if (result.success) {
              analysisData = result.data;
            }
          }
        } else if (consultationStep === 'doctor-review') {
          const doctorNotes = processedHistory
            .filter((msg: any) => msg.role === 'assistant')
            .map((msg: any) => msg.content)
            .join(' ');
          
          const recommendationsResponse = await fetch(`${process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'}/api/ai/doctor-recommendations`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              patientAnalysis: '{}', // Will be passed from frontend
              doctorNotes: doctorNotes,
              urgency: 'medium'
            })
          });
          
          if (recommendationsResponse.ok) {
            const result = await recommendationsResponse.json();
            if (result.success) {
              analysisData = result.data;
            }
          }
        }
      } catch (error) {
        console.error('Error generating analysis data:', error);
      }
    }
    
    // Determine next step
    if (stepComplete) {
      if (consultationStep === 'patient-input') {
        nextStep = 'doctor-review';
      } else if (consultationStep === 'doctor-review') {
        nextStep = 'prescription';
      } else if (consultationStep === 'prescription') {
        nextStep = 'prescription';
      }
    }

    return NextResponse.json({
      transcript: finalUserText,
      response: agentResponse,
      audioBase64: audioBase64,
      nextStep: nextStep,
      stepComplete: stepComplete,
      analysisData: analysisData,
      success: true
    });

  } catch (error) {
    console.error('‚ùå Error in continuous voice processing:', error);
    return NextResponse.json({
      error: 'Error procesando la consulta. Int√©ntelo de nuevo.',
      success: false
    }, { status: 500 });
  }
}

// Helper functions for extracting medical information
function extractSymptoms(history: any[]) {
  const symptoms: string[] = [];
  const userMessages = history
    .filter((msg: any) => msg.role === 'user')
    .map((msg: any) => msg.content)
    .join(' ');
  
  const symptomKeywords = [
    'dolor', 'fiebre', 'tos', 'dolor de cabeza', 'n√°usea', 'v√≥mito', 
    'diarrea', 'fatiga', 'mareo', 'inflamaci√≥n', 'sangrado', 'dificultad para respirar'
  ];
  
  for (const keyword of symptomKeywords) {
    if (userMessages.toLowerCase().includes(keyword)) {
      symptoms.push(keyword);
    }
  }
  return symptoms;
}

function extractMedicalHistory(history: any[]) {
  const userMessages = history
    .filter((msg: any) => msg.role === 'user')
    .map((msg: any) => msg.content)
    .join(' ');
  
  const historyKeywords = ['historial', 'enfermedad', 'condici√≥n', 'diagn√≥stico', 'tratamiento'];
  const sentences = userMessages.split(/[.!?]+/);
  const historySentences = sentences.filter(sentence => 
    historyKeywords.some(keyword => sentence.toLowerCase().includes(keyword))
  );
  
  return historySentences.join('. ');
}

function extractMedications(history: any[]) {
  const medications: string[] = [];
  const userMessages = history
    .filter((msg: any) => msg.role === 'user')
    .map((msg: any) => msg.content)
    .join(' ');
  
  const medicationKeywords = [
    'aspirina', 'paracetamol', 'ibuprofeno', 'melatonina', 'vitaminas', 
    'medicamento', 'pastilla', 'antibi√≥tico', 'antidepresivo'
  ];
  
  for (const keyword of medicationKeywords) {
    if (userMessages.toLowerCase().includes(keyword)) {
      medications.push(keyword);
    }
  }
  return medications;
}
